output_dir: null
train_batch_size: 4
num_epochs: 100
gradient_accumulation_steps: 1
use_ema: True
learning_rate: 1e-4
lr_warmup_steps: 500
save_images_epochs: 1
ddim: True
ddpm_num_inference_steps: 50
with_vae: False
all_circonv: True
pos_encoding: True
semantickitti: True
# HDL-64E normalization
range_mean: 20.
range_std: 40.
model_config:
  sample_size: [1024, 64]
  in_channels: 3
  out_channels: 2
  layers_per_block: 2
  block_out_channels: [128, 128, 256, 256, 512, 512]
  down_block_types: ["DownBlock2D", "DownBlock2D", "DownBlock2D", "DownBlock2D", "AttnDownBlock2D", "DownBlock2D"]
  up_block_types: ["UpBlock2D", "AttnUpBlock2D", "UpBlock2D", "UpBlock2D", "UpBlock2D", "UpBlock2D"]

model_config_name_or_path: null
resolution: [1024, 64]
eval_batch_size: 4
dataloader_num_workers: 8
save_model_epochs: 10
lr_scheduler: cosine
adam_beta1: 0.95
adam_beta2: 0.999
adam_weight_decay: 1e-6
adam_epsilon: 1e-08
ema_inv_gamma: 1.0
ema_power: 0.75
ema_max_decay: 0.9999
push_to_hub: False
hub_token: null
hub_model_id: null
hub_private_repo: False
logger: tensorboard
logging_dir: logs
local_rank: -1
mixed_precision: 'fp16'
gradient_checkpointing: True
prediction_type: epsilon
ddpm_num_steps: 1000
ddpm_beta_schedule: linear
checkpointing_steps: 500
checkpoints_total_limit: 10
resume_from_checkpoint: null
enable_xformers_memory_efficient_attention: False
snr_gamma: null
